{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4575196c-dc93-47ad-9506-c9480a26e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade -q openai langchain langchain-openai langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31a69ec9-d1b9-41c0-beb2-87adeac6d5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "151ea814-bd73-40d5-a7d1-681242883235",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a8c8a3-18de-4da5-9f9b-56366c4b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool, tool\n",
    "from typing import List\n",
    "import json\n",
    "import os\n",
    "import select\n",
    "from datetime import datetime\n",
    "from textwrap import dedent\n",
    "from typing import Dict, List, Optional, TypeVar, Union\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic import ValidationError\n",
    "from typing import Annotated, Any, Dict, List, Literal, Optional, TypedDict, TypeVar, Union\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langchain_core.runnables import Runnable, RunnableConfig, RunnableLambda\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import sys\n",
    "import uuid\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a154e577-cef6-4f0a-a08d-82cd4dbfa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = dedent(\"\"\"\n",
    "### INSTRUÇÕES PARA RESPONDER À PERGUNTA DO HUMANO:\n",
    "\n",
    "1- Entenda a DINÂMICA:\n",
    "\n",
    "    Você é um vendedor online que responde às perguntas do cliente usando o histórico da conversa e as ferramentas disponíveis. \n",
    "\n",
    "2. Passos PARA RESPONDER:\n",
    "\n",
    "    Pergunta: Pergunta do cliente.\n",
    "    Reflexão: \n",
    "        a. Pense passo a passo\n",
    "        b. Analise a pergunta do cliente.\n",
    "        c. Revise o histórico para contexto.\n",
    "        d. Verifique as ferramentas disponíveis.\n",
    "    Ação: A ação a ser tomada. \n",
    "    Entrada: Dados necessários para a ação \n",
    "    Observação: Resultado da ação \n",
    "    Reflexão: Repita se necessário\n",
    "    Resposta Final: Resposta para a pergunta do cliente\n",
    "\n",
    "### Contexto:\n",
    "- Idioma da Resposta: {idioma}\n",
    "- E-mail do Usuário: {email_usuario}\n",
    "- Data de Hoje: {data_hoje}\n",
    "- Dia da Semana: {dia_da_semana}\n",
    "\n",
    "### Histórico da conversa:\n",
    "{chat_history} \n",
    "\n",
    "### Solicitação do cliente:\n",
    "{input}\n",
    "\n",
    "Scratchpad:\n",
    "{agent_scratchpad}\n",
    "\n",
    "===\n",
    "{messages}\n",
    "===\n",
    "\n",
    "**Begin!**\n",
    "\n",
    "Resposta:\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d134985-010a-4286-8739-c4ab459163cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = dedent(\"\"\"Você é um assistente de compras atencioso, educado e prestativo.\n",
    "Sua missão é responder às perguntas do cliente com gentileza, cortesia e precisão.\n",
    "\n",
    "## Regras de Resposta\n",
    "\n",
    "1. Sempre responda com a lista completa de produtos solicitados, incluindo descrições e preços detalhados. Não omita itens nem forneça exemplos parciais.\n",
    "2. Todas as informações devem ser baseadas em dados concretos. Nunca invente produtos ou preços.\n",
    "3. Se um produto não for encontrado, informe quais itens estão ausentes, mas retorne todos os outros produtos disponíveis.\n",
    "4. Caso nenhum produto seja encontrado, informe claramente e sugira ao cliente verificar abreviações ou erros nos nomes.\n",
    "5. Baseie suas respostas exclusivamente no HISTÓRICO DA CONVERSA e CONTEXTO fornecido ou nas ferramentas disponíveis.\n",
    "6. Não procure ou especule informações fora do histórico ou contexto. Se não houver dados suficientes, responda:\n",
    "\"Desculpe, não tenho informações suficientes para responder a essa pergunta com precisão.\"\n",
    "7. Mantenha um tom cordial, educado e informativo. Forneça respostas claras e diretas.\n",
    "\n",
    "## Instruções para Responder\n",
    "\n",
    "Analise o histórico da conversa e responda a solicitação do cliente.\n",
    "\n",
    "# Contexto:\n",
    "- Idioma da Resposta: português\n",
    "- E-mail do Usuário: mrctito@gmail.com\n",
    "- Data de Hoje: 2024-12-17\n",
    "- Dia da Semana: terça\n",
    "\n",
    "# Histórico da conversa:\n",
    "Cliente: Pergunta do Humano:\n",
    "como está o clima?\n",
    "Assistente: None\n",
    " \n",
    "Cliente: Pergunta do Humano:\n",
    "como está o clima?\n",
    "Assistente: None\n",
    " \n",
    "\n",
    "# Solicitação do cliente:\n",
    "como está o clima?\n",
    "\n",
    "---\n",
    "\n",
    "# Scratchpad:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Mensagens:  \n",
    "{{messages}}\n",
    "\n",
    "---\n",
    "\n",
    "Resposta:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d137cd5-3f95-46a4-9ea3-554ea18c26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"como está o clima?\"\n",
    "idioma = \"português\"\n",
    "codigo_cliente = 1\n",
    "email_cliente = \"mrctito@gmail.com\"\n",
    "nome_cliente = \"Paulo\"\n",
    "email_usuario = \"mrctito@gmail.com\"\n",
    "nome_usuario = \"Paulo\"\n",
    "memory_messages = None\n",
    "\n",
    "contexto = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"input\": query,\n",
    "    \"idioma\": idioma,\n",
    "    \"dia_da_semana\": datetime.now().strftime(\"%A\"),\n",
    "    \"data_hoje\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"email_cliente\": email_usuario,\n",
    "    \"nome_cliente\": nome_usuario,\n",
    "    \"email_usuario\": email_usuario,\n",
    "    \"nome_usuario\": nome_usuario,\n",
    "    \"chat_history\": memory_messages if memory_messages else \" \",\n",
    "    \"agent_scratchpad\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02237544-9c0f-49b3-97a1-b482d3417d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def tool_informa_o_clima() -> str:\n",
    "    \"\"\"\n",
    "    Útil para informar o clima atual.\n",
    "    \"\"\"\n",
    "    return [\"O clima está estável com sol.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f903345-cfb8-4f0a-9bc0-f056fad054c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "tools.append(tool_informa_o_clima)\n",
    "tools_names = \"\\n\\n\".join([f\"Ferramenta: {tool.name}\\nDescrição: {tool.description}\" for tool in tools])\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "042f4c69-646a-40c5-97ca-43f39db25d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=OPENAI_MODEL,\n",
    "                 api_key=OPENAI_API_KEY,\n",
    "                 temperature=0.7,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d43aac1-1ce6-454e-b135-3196d71472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5651b745-c53c-4ddb-9745-5438b0946004",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", prompt_str),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58d2aefe-0427-4d9c-b57d-78fc500b6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_runnable = primary_assistant_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad31fde9-97eb-4ad8-a806-6331f1ccb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c091f3e-b9e3-4de0-ba4c-a770cb8f0790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1f356c9-46c4-454e-8a5c-50fbc6000af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f94b7e4640>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"tools\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "async def call_model(state: State, config: RunnableConfig):\n",
    "    messages = state[\"messages\"]\n",
    "    # Note: Passing the config through explicitly is required for python < 3.11\n",
    "    # Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks\n",
    "\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    contexto = configuration.get(\"contexto\", {})\n",
    "    user_id = configuration.get(\"user_id\", None)\n",
    "    state = {**state, \"user_info\": user_id, **contexto}\n",
    "    \n",
    "    response = await assistant_runnable.ainvoke(messages, config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Next we pass in the path map - all the nodes this edge could go to\n",
    "    [\"tools\", END],\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbae15-98ac-4050-8814-efccc1adf7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76066bab-e837-4d83-81f8-a1fe9e680fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # fetch the user's id\n",
    "        \"user_id\": email_usuario,\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "        \"contexto\": contexto\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06b601f6-ffca-4b23-a68d-a0520da4df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'agent_scratchpad': '',\n",
      " 'chat_history': ' ',\n",
      " 'data_hoje': '2024-12-18',\n",
      " 'dia_da_semana': 'Wednesday',\n",
      " 'email_cliente': 'mrctito@gmail.com',\n",
      " 'email_usuario': 'mrctito@gmail.com',\n",
      " 'idioma': 'português',\n",
      " 'input': 'como está o clima?',\n",
      " 'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={})],\n",
      " 'nome_cliente': 'Paulo',\n",
      " 'nome_usuario': 'Paulo'}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> {'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='[\"O clima está estável com sol.\"]', name='tool_informa_o_clima', tool_call_id='call_HSceJc879mo8PG0WQ9E1CXZY')]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='[\"O clima está estável com sol.\"]', name='tool_informa_o_clima', id='d88b4188-433c-414a-9f6a-bb5fb177126c', tool_call_id='call_HSceJc879mo8PG0WQ9E1CXZY')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='[\"O clima está estável com sol.\"]', name='tool_informa_o_clima', id='d88b4188-433c-414a-9f6a-bb5fb177126c', tool_call_id='call_HSceJc879mo8PG0WQ9E1CXZY')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> AIMessage(content='O clima está estável com sol. Se precisar de mais informações ou ajuda, fique à vontade para perguntar!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 867, 'total_tokens': 890, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-e375e8e6-d424-4ce9-b7d7-937e67939956-0', usage_metadata={'input_tokens': 867, 'output_tokens': 23, 'total_tokens': 890, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='1b1691ab-ccff-4e85-9a8e-d71f067162ad'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6adb27de-50a8-4388-921e-ad77dbe234f9-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_HSceJc879mo8PG0WQ9E1CXZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='[\"O clima está estável com sol.\"]', name='tool_informa_o_clima', id='d88b4188-433c-414a-9f6a-bb5fb177126c', tool_call_id='call_HSceJc879mo8PG0WQ9E1CXZY'),\n",
      "              AIMessage(content='O clima está estável com sol. Se precisar de mais informações ou ajuda, fique à vontade para perguntar!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 867, 'total_tokens': 890, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-e375e8e6-d424-4ce9-b7d7-937e67939956-0', usage_metadata={'input_tokens': 867, 'output_tokens': 23, 'total_tokens': 890, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "resultado = await graph.ainvoke(contexto, config, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b56dfef-dc17-4e00-93c1-f21041c4eed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='como está o clima?', additional_kwargs={}, response_metadata={}, id='50d48c09-fe4e-4f68-b3d3-b048b68c805d'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZXqfzfc7fKkfessWqXYsm4Tw', 'function': {'arguments': '{}', 'name': 'tool_informa_o_clima'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 460, 'total_tokens': 474, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-931165a6-3c46-4fd7-b470-5a1d9474a8a4-0', tool_calls=[{'name': 'tool_informa_o_clima', 'args': {}, 'id': 'call_ZXqfzfc7fKkfessWqXYsm4Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 460, 'output_tokens': 14, 'total_tokens': 474, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='[\"O clima está estável com sol.\"]', name='tool_informa_o_clima', id='b845f7a6-1e34-4678-9209-140735ec76da', tool_call_id='call_ZXqfzfc7fKkfessWqXYsm4Tw'),\n",
      "              AIMessage(content='O clima está estável e ensolarado. Se precisar de mais informações ou detalhes, estou à disposição!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 867, 'total_tokens': 890, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae33419d-83b9-4a6c-ba2a-ea3318d72998-0', usage_metadata={'input_tokens': 867, 'output_tokens': 23, 'total_tokens': 890, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b7582-60c8-4d24-adcb-434e54e84e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca3409-0ef6-482f-921d-4dce1e6e3c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d4ca3-b148-4219-b883-20b77b65dbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55c768-0dc8-4a28-857a-e7e16f17755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
